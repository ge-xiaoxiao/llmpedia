# 系统设计题


## 如何优化GPU集群/单节点的利用率？<Badge text="重要" type="danger" />

**单节点GPU**

- 增大Batch Size；梯度累积
- 算子融合
- 混合精度
- 消除CPU瓶颈

**GPU集群优化**

- 核心问题：小任务零散占用GPU, 导致大任务（如8卡训练）因无法申请到连续的多卡资源而排队，集群整体利用率低
- 我们可以为大任务设置高优先级，预留大任务所需的GPU资源，确保任务能一次性启动，避免碎片化
- 可以将分散在各节点的小任务迁移合并，释放连续的GPU资源块
- 弹性扩缩容，训练的时候动态调整并行策略；推理的时候自动扩缩容根据请求的量

**分布式训练：**

- 尽可能实现通信和计算的异步重叠，可以通过分子批次来实现

**任务设计层面**

- 将多个小推理任务打包成一个batch处理，提升GPU


## 如何优化模型训练中的访存？<Badge text="重要" type="danger" />

- 减少仿存的数据量
    - 混合精度训练（FP16/BF16）, 4字节→2字节 （优化器状态、损失函数计算用32）
    - 激活值压缩 / 稀疏化，Top-K稀疏
    - 参数共享/低秩分解：Transformer的Embedding层与输出层共享权重；LoRA
- 可以做算子的融合，比如FlashAttention对 Q/K/V 计算→Attention得分→softmax → V加权，融合成一个Kernel
- 重计算，仅仅保留部分的激活值，反向传播时重新进行一遍前向的过程
- 可以做异步，重叠计算与仿存操作
- 并行的时候选择合适的选型策略，比方说做张量并行时，将同一Attention头的Q/K/V分配到同一节点的GPU,减少跨节点通信；