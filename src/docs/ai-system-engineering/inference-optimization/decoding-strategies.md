# 解码策略

## PD 分离 <Badge text="掌握" type="tip" />

PD 分离，即预填充（Prefill）与解码（Decode）阶段的分离调度。在传统流程中，一个请求必须完整执行完耗时的长提示词预填充计算后，才能开始逐个Token的解码输出，这会导致首个输出Token延迟很高，且在解码时GPU计算核心利用率很低。

PD 分离将这两个阶段解耦为两个独立的虚拟队列。当一批请求到达时，系统优先将所有请求的预填充计算集中起来，打包成一个大型计算任务执行，以最大化GPU的并行计算能力，实现高吞吐的“预填充阶段”。完成之后，这些请求进入解码队列。解码阶段的特点是计算量小但频繁，系统会以更高的频率调度解码步骤，每次调度一批请求进行单个Token的解码。这样，用户能更快地收到首Token，且解码过程流畅。这种“集中预填充、高频小批量解码”的模式，有效地兼顾了吞吐量与延迟，是当前高性能推理服务的标准调度模式。

## 投机解码 <Badge text="重要" type="danger" />

投机解码是一种激进的、旨在减少解码步骤总数的根本性优化。其核心思想是让一个小模型（草案模型） 去“猜测”大模型（目标模型）后续可能生成的多个Token，然后由大模型一次性对这些猜测进行并行验证。这个过程类似于“草稿-校对”：小模型快速生成一个候选Token序列（草案），大模型并不从头运行，而是并行地检查这个序列的每一步是否正确。它会接受所有正确的连续前缀，并基于第一个错误的位置重新开始生成。

投机解码的关键价值在于，它用一次廉价的小模型前向传播和一次（相对昂贵的）大模型并行验证，可能换回多个被接受的Token。理想情况下，这能直接跳过多个解码步骤，从而将解码吞吐量提升数倍。其性能提升取决于草案模型的质量与速度，以及两者之间的协同。它本质上是用计算资源（并行验证能力）来换取更少的串行解码步骤，是突破自回归解码固有延迟瓶颈的最有前景的技术之一。
