import{_ as r}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,b as e,d as n,e as o,r as i,o as s}from"./app-CRXmQLa0.js";const p={},d={id:"flashattention-v1",tabindex:"-1"},m={class:"header-anchor",href:"#flashattention-v1"},u={id:"flashattention-v2",tabindex:"-1"},g={class:"header-anchor",href:"#flashattention-v2"},f={id:"flashattention-v3",tabindex:"-1"},x={class:"header-anchor",href:"#flashattention-v3"},h={id:"deepspeed-zero-1-2-3",tabindex:"-1"},y={class:"header-anchor",href:"#deepspeed-zero-1-2-3"},R={id:"deepspeed-zero-1-2-3-通信流程",tabindex:"-1"},b={class:"header-anchor",href:"#deepspeed-zero-1-2-3-通信流程"},A={id:"megatron-lm",tabindex:"-1"},v={class:"header-anchor",href:"#megatron-lm"},O={id:"llama-factory",tabindex:"-1"},P={class:"header-anchor",href:"#llama-factory"};function G(M,t){const l=i("Badge");return s(),a("div",null,[t[7]||(t[7]=e("h1",{id:"训练框架",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#训练框架"},[e("span",null,"训练框架")])],-1)),e("h2",d,[e("a",m,[e("span",null,[t[0]||(t[0]=n("FlashAttention v1 ",-1)),o(l,{text:"重要",type:"danger"})])])]),t[8]||(t[8]=e("p",null,[e("a",{href:"https://www.bilibili.com/video/BV1fG9rYWEA8/?spm_id_from=333.337.search-card.all.click&vd_source=3a13163d3fccf0112a072a3a483b9046",target:"_blank",rel:"noopener noreferrer"},"推荐教程")],-1)),t[9]||(t[9]=e("ul",null,[e("li",null,[e("p",null,"分块，Kernel Fusion，将多个独立的GPU操作（Kernel）合并为一个定制的Kernel")]),e("li",null,[e("p",null,"Backward Recomputation，在反向传播过程中，重新计算前向传播的部分结果，而不是从HBM中读取，虽然这会增加一些计算量，但显著减少了HBM的内存占用，使得模型可以处理更长的序列，或者在有限的GPU内存下使用更大的批次大小")]),e("li",null,[e("p",null,"Softmax Tiling：Attention分数矩阵分割成若干个小的块（Tile），然后逐个加载到SRAM中进行Softmax计算。在计算每个Tile的Softmax时，算法会利用之前计算的块的信息，以保证最终结果的正确性")])],-1)),t[10]||(t[10]=e("figure",null,[e("a",{href:"https://youke.xn--y7xa690gmna.cn/s1/2026/01/30/697cb5d25556c.webp",target:"_blank",rel:"noopener noreferrer"},[e("img",{src:"https://youke.xn--y7xa690gmna.cn/s1/2026/01/30/697cb5d25556c.webp",alt:"",tabindex:"0",loading:"lazy"})]),e("figcaption")],-1)),e("h2",u,[e("a",g,[e("span",null,[t[1]||(t[1]=n("FlashAttention v2 ",-1)),o(l,{text:"重要",type:"danger"})])])]),t[11]||(t[11]=e("p",null,"FlashAttention v2 是在 v1 基础上进一步优化的注意力计算算法，核心目标是通过更精细的硬件感知设计减少内存访问开销。其主要改进包括三个方面：",-1)),t[12]||(t[12]=e("ul",null,[e("li",null,[e("p",null,"一是算法重排，通过调整计算顺序减少非矩阵乘法操作（如 softmax 归一化）的中间存储，将更多计算保持在 SRAM 高速缓存中；")]),e("li",null,[e("p",null,"二是更好的并行化策略，针对序列维度进行更有效的切分，充分利用 GPU 的线程块和线程束资源；")]),e("li",null,[e("p",null,"三是减少了 warps 之间的同步开销，通过改进的工作分配降低通信成本。这些优化使得 v2 相比 v1 实现了约 2 倍的训练速度提升，在长序列处理（如 8K 以上上下文）时优势尤为明显，同时保持了与标准注意力完全相同的数值结果。")])],-1)),e("h2",f,[e("a",x,[e("span",null,[t[2]||(t[2]=n("FlashAttention v3 ",-1)),o(l,{text:"掌握",type:"tip"})])])]),t[13]||(t[13]=e("p",null,"FlashAttention v3 在前代基础上进一步针对新硬件架构优化，特别是对NVIDIA Hopper架构的Tensor Core进行专门适配。主要创新包括对FP8等新数据类型的支持，通过动态稀疏性利用智能跳过注意力矩阵中的低权重区域，以及更灵活的切分策略以适应多样化的工作负载。",-1)),t[14]||(t[14]=e("p",null,"核心改进体现在三个层面：首先是计算模式优化，利用新一代GPU的异步复制和分布式共享内存特性，进一步隐藏内存访问延迟；其次是硬件原语利用，深度集成CUDA Graph和新型Tensor Core指令集；最后是算法适应性增强，原生支持更多注意力变体如滑动窗口、块稀疏等结构化模式。",-1)),t[15]||(t[15]=e("p",null,"实际性能上，v3在H100等新硬件上相比v2又有1.5-2倍提升，特别在大批量、长序列的训练场景中效果显著。但需注意v3硬件依赖性更强，在老一代GPU上可能无法充分发挥优势，且对某些特殊注意力模式的支持仍在完善中。",-1)),e("h2",h,[e("a",y,[e("span",null,[t[3]||(t[3]=n("Deepspeed ZeRO 1/2/3 ",-1)),o(l,{text:"重要",type:"danger"})])])]),t[16]||(t[16]=e("p",null,"DeepSpeed ZeRO是一套分级内存优化系统，通过数据并行框架内的智能状态划分消除冗余存储。其核心理念是将模型训练状态进行渐进式划分，从优化器状态到梯度再到参数，逐级增加划分粒度以换取更大的内存节省。",-1)),t[17]||(t[17]=e("p",null,[n("具体来看，ZeRO-1主要划分"),e("strong",null,"优化器状态"),n("，每个GPU只存储和更新完整优化器状态的一部分，节省约4倍内存；ZeRO-2增加"),e("strong",null,"梯度划分"),n("，反向传播后梯度被分区存储，仅在全规约时进行通信，内存节省扩大至约8倍；ZeRO-3则进一步划分"),e("strong",null,"模型参数"),n("，每个GPU仅缓存部分参数，通过动态获取和释放参数实现近乎线性的内存缩放，可训练比单个GPU内存大数十倍的模型。")],-1)),t[18]||(t[18]=e("p",null,"选择策略时需要考虑通信开销与内存节省的权衡：ZeRO-1通信最少，适合网络带宽有限场景；ZeRO-3内存节省最大，但需要高带宽互联；实际部署中常采用混合策略，如ZeRO-2配合梯度累积。ZeRO Offload技术还能将部分状态卸载到CPU内存，进一步扩展训练规模。",-1)),e("h2",R,[e("a",b,[e("span",null,[t[4]||(t[4]=n("Deepspeed ZeRO 1/2/3 通信流程 ",-1)),o(l,{text:"重要",type:"danger"})])])]),t[19]||(t[19]=e("p",null,[e("strong",null,"ZeRO-1：优化器状态划分"),e("br"),n(" ZeRO-1的通信模式最为简单直接。在前向和反向传播过程中，每个进程都持有完整的模型参数和梯度，因此无需任何额外通信，计算完全独立。通信开销集中在优化器步骤：反向传播后，各进程首先对完整梯度进行All-Reduce求平均（与传统数据并行相同），接着每个进程仅更新自己负责的优化器状态分区，最后通过All-Gather广播更新后的参数分区，使所有进程获得完整参数。总通信量约为模型参数量的3倍，与传统数据并行完全一致，但通过优化器状态划分实现了约4倍的内存节省。")],-1)),t[20]||(t[20]=e("p",null,[e("strong",null,"ZeRO-2：增加梯度划分"),e("br"),n(" ZeRO-2引入了更复杂的通信模式以换取更大的内存节省。前向传播需要参数收集通信，因为每个进程只存储自己负责的梯度分区对应的参数分区，计算前必须通过All-Gather从所有进程收集完整参数，每次前向传播通信量为参数量Ψ。反向传播分为两个阶段：各进程先独立计算完整梯度，然后通过Reduce-Scatter操作进行梯度规约，各进程只保留自己负责的梯度分区，通信量为Ψ（比传统减少一半）。优化器步骤中，各进程仅更新自己分区的参数，无需额外同步通信。总通信量为2Ψ，相比传统数据并行的3Ψ减少约33%，同时内存节省扩大到约8倍。")],-1)),t[21]||(t[21]=e("p",null,[e("strong",null,"ZeRO-3：完整参数划分"),e("br"),n(" ZeRO-3采用最激进的划分策略，通信模式也最为复杂。前向传播需要实时参数获取，每个层计算时动态通过All-Gather获取所需参数，采用持久化进程组和计算-通信重叠等技术优化。反向传播同样需要All-Gather获取完整参数，然后通过Reduce-Scatter进行梯度规约和分区。参数更新后采用惰性广播机制，在下次需要时自动获取新参数。")],-1)),t[22]||(t[22]=e("p",null,"ZeRO-3的通信特点是细粒度和高频次，每层都可能触发通信，但单次通信量较小。实际通信开销通常高于理论值2Ψ，因为存在元数据通信和同步开销。在高速互联环境下，ZeRO-3效率接近ZeRO-2；在慢速网络中性能下降明显。其最大优势是内存节省与GPU数量成比例，适合训练远超单卡内存容量的超大模型。",-1)),e("h2",A,[e("a",v,[e("span",null,[t[5]||(t[5]=n("Megatron-LM ",-1)),o(l,{text:"掌握",type:"tip"})])])]),t[23]||(t[23]=e("p",null,"Megatron-LM的核心贡献是多维度并行策略的协同设计，将张量并行、流水线并行和数据并行有机结合。张量并行专注于单层内部的切分，将矩阵运算分布到多个设备，通过All-Reduce通信保持数学等价性；流水线并行实施层间切分，形成模型计算流水线，需要仔细调度微批次以最小化设备闲置时间；数据并行则进行批次维度切分，各设备处理不同数据分片。",-1)),t[24]||(t[24]=e("p",null,"该框架特别对Transformer架构进行了深度优化：注意力计算分割将多头注意力分散到不同设备；层归一化位置调整减少通信需求；梯度累积策略平衡内存与吞吐量。Megatron的通信优化尤为突出，通过计算与通信重叠、梯度压缩等技术，在数千GPU集群上仍能保持较高计算效率。",-1)),t[25]||(t[25]=e("p",null,"实际部署经验表明，张量并行最适合小规模紧密连接设备（如NVLink连接的8卡节点），流水线并行适合设备间带宽有限场景，而3D并行组合可扩展至数万GPU训练万亿参数模型。调优时需特别注意气泡时间、通信开销和负载平衡的权衡。",-1)),e("h2",O,[e("a",P,[e("span",null,[t[6]||(t[6]=n("LLaMA-Factory ",-1)),o(l,{text:"了解",type:"info"})])])]),t[26]||(t[26]=e("p",null,"LLaMA-Factory定位为端到端的LLaMA模型工程平台，将模型微调、评估和部署流程工具化、标准化。其主要价值在于降低大模型定制化门槛，通过模块化设计支持从数据预处理到模型服务的完整生命周期。",-1)),t[27]||(t[27]=e("p",null,"框架设计上强调灵活性与效率的平衡：一方面支持多种微调范式，从全参数微调到参数高效方法如LoRA、QLoRA，再到强化学习对齐如PPO、DPO；另一方面提供资源感知优化，包括梯度检查点、混合精度训练、CPU卸载等技术，使大模型能在消费级硬件上微调。",-1)),t[28]||(t[28]=e("p",null,"实际应用中的关键特性包括：统一的数据接口支持多种格式转换；可配置的训练流水线支持多阶段微调；集成的评估体系涵盖从基础能力到安全对齐的多维度测试；便捷的部署工具支持量化、剪枝等压缩技术。",-1))])}const w=r(p,[["render",G]]),U=JSON.parse('{"path":"/docs/ai-system-engineering/training-optimization/training-frameworks.html","title":"训练框架","lang":"zh-CN","frontmatter":{"description":"训练框架 FlashAttention v1 推荐教程 分块，Kernel Fusion，将多个独立的GPU操作（Kernel）合并为一个定制的Kernel Backward Recomputation，在反向传播过程中，重新计算前向传播的部分结果，而不是从HBM中读取，虽然这会增加一些计算量，但显著减少了HBM的内存占用，使得模型可以处理更长的序列，...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"训练框架\\",\\"image\\":[\\"https://youke.xn--y7xa690gmna.cn/s1/2026/01/30/697cb5d25556c.webp\\"],\\"dateModified\\":\\"2026-01-30T14:31:16.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"LLMPedia\\",\\"url\\":\\"https://llmpedia.online\\"}]}"],["meta",{"property":"og:url","content":"https://llmpedia.online/docs/ai-system-engineering/training-optimization/training-frameworks.html"}],["meta",{"property":"og:site_name","content":"LLMPedia"}],["meta",{"property":"og:title","content":"训练框架"}],["meta",{"property":"og:description","content":"训练框架 FlashAttention v1 推荐教程 分块，Kernel Fusion，将多个独立的GPU操作（Kernel）合并为一个定制的Kernel Backward Recomputation，在反向传播过程中，重新计算前向传播的部分结果，而不是从HBM中读取，虽然这会增加一些计算量，但显著减少了HBM的内存占用，使得模型可以处理更长的序列，..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://youke.xn--y7xa690gmna.cn/s1/2026/01/30/697cb5d25556c.webp"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2026-01-30T14:31:16.000Z"}],["meta",{"property":"article:modified_time","content":"2026-01-30T14:31:16.000Z"}]]},"git":{"createdTime":1769771827000,"updatedTime":1769783476000,"contributors":[{"name":"ge-xiaoxiao","username":"ge-xiaoxiao","email":"marshall_gefxiang@163.com","commits":1,"url":"https://github.com/ge-xiaoxiao"},{"name":"Marshall-Ge","username":"Marshall-Ge","email":"1004083966@qq.com","commits":1,"url":"https://github.com/Marshall-Ge"}]},"readingTime":{"minutes":8.04,"words":2413},"filePathRelative":"docs/ai-system-engineering/training-optimization/training-frameworks.md","autoDesc":true}');export{w as comp,U as data};
