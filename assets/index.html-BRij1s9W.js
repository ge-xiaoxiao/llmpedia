import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,a as n,o as t}from"./app-CKtwmAdt.js";const e={};function l(h,i){return t(),a("div",null,[...i[0]||(i[0]=[n(`<h1 id="gpu-cuda面试题" tabindex="-1"><a class="header-anchor" href="#gpu-cuda面试题"><span>GPU/CUDA面试题</span></a></h1><p>本章节涵盖GPU并行计算、CUDA编程、显存优化等相关面试题。</p><h2 id="核心知识点" tabindex="-1"><a class="header-anchor" href="#核心知识点"><span>核心知识点</span></a></h2><h3 id="_1-cuda编程基础" tabindex="-1"><a class="header-anchor" href="#_1-cuda编程基础"><span>1. CUDA编程基础</span></a></h3><ul><li><strong>GPU架构</strong>：SM、warp、线程层次结构</li><li><strong>CUDA编程模型</strong>：网格、块、线程的组织</li><li><strong>内存层次</strong>：全局内存、共享内存、寄存器、常量内存</li><li><strong>同步机制</strong>：__syncthreads()、原子操作</li></ul><h3 id="_2-性能优化" tabindex="-1"><a class="header-anchor" href="#_2-性能优化"><span>2. 性能优化</span></a></h3><ul><li><strong>内存访问优化</strong>：合并访问、bank conflict避免</li><li><strong>计算优化</strong>：指令级并行、warp调度</li><li><strong>显存管理</strong>：内存分配、数据传输优化</li><li><strong>流与事件</strong>：异步操作、重叠计算与传输</li></ul><h3 id="_3-高级特性" tabindex="-1"><a class="header-anchor" href="#_3-高级特性"><span>3. 高级特性</span></a></h3><ul><li><strong>Tensor Core</strong>：混合精度计算、矩阵运算加速</li><li><strong>NVLink/NVSwitch</strong>：多GPU通信</li><li><strong>CUDA Graph</strong>：计算图优化</li><li><strong>MPS</strong>：多进程服务</li></ul><h2 id="常见面试题" tabindex="-1"><a class="header-anchor" href="#常见面试题"><span>常见面试题</span></a></h2><h3 id="基础题" tabindex="-1"><a class="header-anchor" href="#基础题"><span>基础题</span></a></h3><ol><li><p><strong>Q：解释CUDA中的网格、块和线程的关系</strong><br> A：在CUDA编程模型中，网格包含多个线程块...</p></li><li><p><strong>Q：什么是bank conflict？如何避免？</strong><br> A：bank conflict发生在共享内存访问中...</p></li></ol><h3 id="进阶题" tabindex="-1"><a class="header-anchor" href="#进阶题"><span>进阶题</span></a></h3><ol><li><p><strong>Q：如何优化矩阵乘法的CUDA实现？</strong><br> A：可以使用共享内存进行平铺优化...</p></li><li><p><strong>Q：解释CUDA中的异步操作和流</strong><br> A：CUDA流允许并发执行多个操作...</p></li></ol><h2 id="实战问题" tabindex="-1"><a class="header-anchor" href="#实战问题"><span>实战问题</span></a></h2><h3 id="性能调优" tabindex="-1"><a class="header-anchor" href="#性能调优"><span>性能调优</span></a></h3><ol><li><strong>分析并优化一个CUDA核函数的性能</strong></li><li><strong>设计支持动态批处理的高性能推理引擎</strong></li></ol><h3 id="代码实现" tabindex="-1"><a class="header-anchor" href="#代码实现"><span>代码实现</span></a></h3><div class="language-cpp line-numbers-mode" data-highlighter="shiki" data-ext="cpp" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-cpp"><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">// 简单的向量加法CUDA核函数</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">__global__ </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">void</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> vectorAdd</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">float*</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> A, </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">float*</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> B, </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">float*</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> C, </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">int</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> n) {</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    int</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> i </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> blockIdx</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">x</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> *</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> blockDim</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">x</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> +</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> threadIdx</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">x</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">;</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    if</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> (i </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">&lt;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> n) {</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        C</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[i] </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> A</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[i] </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">+</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> B</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[i];</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    }</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,19)])])}const d=s(e,[["render",l]]),k=JSON.parse('{"path":"/docs/gpu-cuda/","title":"GPU/CUDA面试题","lang":"zh-CN","frontmatter":{"description":"GPU/CUDA面试题 本章节涵盖GPU并行计算、CUDA编程、显存优化等相关面试题。 核心知识点 1. CUDA编程基础 GPU架构：SM、warp、线程层次结构 CUDA编程模型：网格、块、线程的组织 内存层次：全局内存、共享内存、寄存器、常量内存 同步机制：__syncthreads()、原子操作 2. 性能优化 内存访问优化：合并访问、bank...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"GPU/CUDA面试题\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2026-01-29T10:42:58.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"LLMPedia\\",\\"url\\":\\"https://llmpedia.example.com\\"}]}"],["meta",{"property":"og:url","content":"https://llmpedia.example.com/llmpedia/docs/gpu-cuda/"}],["meta",{"property":"og:site_name","content":"LLMPedia - 大模型面试八股题"}],["meta",{"property":"og:title","content":"GPU/CUDA面试题"}],["meta",{"property":"og:description","content":"GPU/CUDA面试题 本章节涵盖GPU并行计算、CUDA编程、显存优化等相关面试题。 核心知识点 1. CUDA编程基础 GPU架构：SM、warp、线程层次结构 CUDA编程模型：网格、块、线程的组织 内存层次：全局内存、共享内存、寄存器、常量内存 同步机制：__syncthreads()、原子操作 2. 性能优化 内存访问优化：合并访问、bank..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2026-01-29T10:42:58.000Z"}],["meta",{"property":"article:modified_time","content":"2026-01-29T10:42:58.000Z"}]]},"git":{"createdTime":1769683378000,"updatedTime":1769683378000,"contributors":[{"name":"ge-xiaoxiao","username":"ge-xiaoxiao","email":"marshall_gefxiang@163.com","commits":1,"url":"https://github.com/ge-xiaoxiao"}]},"readingTime":{"minutes":1.32,"words":397},"filePathRelative":"docs/gpu-cuda/README.md","autoDesc":true}');export{d as comp,k as data};
