import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,b as e,d as i,e as n,a as r,r as s,o as p}from"./app-CRXmQLa0.js";const m={},d={id:"如何优化gpu集群-单节点的利用率",tabindex:"-1"},c={class:"header-anchor",href:"#如何优化gpu集群-单节点的利用率"},u={id:"如何优化模型训练中的访存",tabindex:"-1"},g={class:"header-anchor",href:"#如何优化模型训练中的访存"};function h(P,t){const l=s("Badge");return p(),a("div",null,[t[2]||(t[2]=e("h1",{id:"系统设计题",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#系统设计题"},[e("span",null,"系统设计题")])],-1)),e("h2",d,[e("a",c,[e("span",null,[t[0]||(t[0]=i("如何优化GPU集群/单节点的利用率？",-1)),n(l,{text:"重要",type:"danger"})])])]),t[3]||(t[3]=r("<p><strong>单节点GPU</strong></p><ul><li>增大Batch Size；梯度累积</li><li>算子融合</li><li>混合精度</li><li>消除CPU瓶颈</li></ul><p><strong>GPU集群优化</strong></p><ul><li>核心问题：小任务零散占用GPU, 导致大任务（如8卡训练）因无法申请到连续的多卡资源而排队，集群整体利用率低</li><li>我们可以为大任务设置高优先级，预留大任务所需的GPU资源，确保任务能一次性启动，避免碎片化</li><li>可以将分散在各节点的小任务迁移合并，释放连续的GPU资源块</li><li>弹性扩缩容，训练的时候动态调整并行策略；推理的时候自动扩缩容根据请求的量</li></ul><p><strong>分布式训练：</strong></p><ul><li>尽可能实现通信和计算的异步重叠，可以通过分子批次来实现</li></ul><p><strong>任务设计层面</strong></p><ul><li>将多个小推理任务打包成一个batch处理，提升GPU</li></ul>",8)),e("h2",u,[e("a",g,[e("span",null,[t[1]||(t[1]=i("如何优化模型训练中的访存？",-1)),n(l,{text:"重要",type:"danger"})])])]),t[4]||(t[4]=e("ul",null,[e("li",null,[i("减少仿存的数据量 "),e("ul",null,[e("li",null,"混合精度训练（FP16/BF16）, 4字节→2字节 （优化器状态、损失函数计算用32）"),e("li",null,"激活值压缩 / 稀疏化，Top-K稀疏"),e("li",null,"参数共享/低秩分解：Transformer的Embedding层与输出层共享权重；LoRA")])]),e("li",null,"可以做算子的融合，比如FlashAttention对 Q/K/V 计算→Attention得分→softmax → V加权，融合成一个Kernel"),e("li",null,"重计算，仅仅保留部分的激活值，反向传播时重新进行一遍前向的过程"),e("li",null,"可以做异步，重叠计算与仿存操作"),e("li",null,"并行的时候选择合适的选型策略，比方说做张量并行时，将同一Attention头的Q/K/V分配到同一节点的GPU,减少跨节点通信；")],-1))])}const x=o(m,[["render",h]]),y=JSON.parse('{"path":"/docs/practice-interview/system-design.html","title":"系统设计题","lang":"zh-CN","frontmatter":{"description":"系统设计题 如何优化GPU集群/单节点的利用率？ 单节点GPU 增大Batch Size；梯度累积 算子融合 混合精度 消除CPU瓶颈 GPU集群优化 核心问题：小任务零散占用GPU, 导致大任务（如8卡训练）因无法申请到连续的多卡资源而排队，集群整体利用率低 我们可以为大任务设置高优先级，预留大任务所需的GPU资源，确保任务能一次性启动，避免碎片化 ...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"系统设计题\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2026-01-30T14:31:16.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"LLMPedia\\",\\"url\\":\\"https://llmpedia.online\\"}]}"],["meta",{"property":"og:url","content":"https://llmpedia.online/docs/practice-interview/system-design.html"}],["meta",{"property":"og:site_name","content":"LLMPedia"}],["meta",{"property":"og:title","content":"系统设计题"}],["meta",{"property":"og:description","content":"系统设计题 如何优化GPU集群/单节点的利用率？ 单节点GPU 增大Batch Size；梯度累积 算子融合 混合精度 消除CPU瓶颈 GPU集群优化 核心问题：小任务零散占用GPU, 导致大任务（如8卡训练）因无法申请到连续的多卡资源而排队，集群整体利用率低 我们可以为大任务设置高优先级，预留大任务所需的GPU资源，确保任务能一次性启动，避免碎片化 ..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2026-01-30T14:31:16.000Z"}],["meta",{"property":"article:modified_time","content":"2026-01-30T14:31:16.000Z"}]]},"git":{"createdTime":1769771827000,"updatedTime":1769783476000,"contributors":[{"name":"ge-xiaoxiao","username":"ge-xiaoxiao","email":"marshall_gefxiang@163.com","commits":1,"url":"https://github.com/ge-xiaoxiao"},{"name":"Marshall-Ge","username":"Marshall-Ge","email":"1004083966@qq.com","commits":1,"url":"https://github.com/Marshall-Ge"}]},"readingTime":{"minutes":1.55,"words":464},"filePathRelative":"docs/practice-interview/system-design.md","autoDesc":true}');export{x as comp,y as data};
