import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as r,b as t,d as n,e as i,r as s,o as l}from"./app-C0LVkWS9.js";const d={},p={id:"pd-分离",tabindex:"-1"},m={class:"header-anchor",href:"#pd-分离"},c={id:"投机解码",tabindex:"-1"},g={class:"header-anchor",href:"#投机解码"};function h(u,e){const o=s("Badge");return l(),r("div",null,[e[2]||(e[2]=t("h1",{id:"解码策略",tabindex:"-1"},[t("a",{class:"header-anchor",href:"#解码策略"},[t("span",null,"解码策略")])],-1)),t("h2",p,[t("a",m,[t("span",null,[e[0]||(e[0]=n("PD 分离 ",-1)),i(o,{text:"掌握",type:"tip"})])])]),e[3]||(e[3]=t("p",null,"PD 分离，即预填充（Prefill）与解码（Decode）阶段的分离调度。在传统流程中，一个请求必须完整执行完耗时的长提示词预填充计算后，才能开始逐个Token的解码输出，这会导致首个输出Token延迟很高，且在解码时GPU计算核心利用率很低。",-1)),e[4]||(e[4]=t("p",null,"PD 分离将这两个阶段解耦为两个独立的虚拟队列。当一批请求到达时，系统优先将所有请求的预填充计算集中起来，打包成一个大型计算任务执行，以最大化GPU的并行计算能力，实现高吞吐的“预填充阶段”。完成之后，这些请求进入解码队列。解码阶段的特点是计算量小但频繁，系统会以更高的频率调度解码步骤，每次调度一批请求进行单个Token的解码。这样，用户能更快地收到首Token，且解码过程流畅。这种“集中预填充、高频小批量解码”的模式，有效地兼顾了吞吐量与延迟，是当前高性能推理服务的标准调度模式。",-1)),t("h2",c,[t("a",g,[t("span",null,[e[1]||(e[1]=n("投机解码 ",-1)),i(o,{text:"重要",type:"danger"})])])]),e[5]||(e[5]=t("p",null,"投机解码是一种激进的、旨在减少解码步骤总数的根本性优化。其核心思想是让一个小模型（草案模型） 去“猜测”大模型（目标模型）后续可能生成的多个Token，然后由大模型一次性对这些猜测进行并行验证。这个过程类似于“草稿-校对”：小模型快速生成一个候选Token序列（草案），大模型并不从头运行，而是并行地检查这个序列的每一步是否正确。它会接受所有正确的连续前缀，并基于第一个错误的位置重新开始生成。",-1)),e[6]||(e[6]=t("p",null,"投机解码的关键价值在于，它用一次廉价的小模型前向传播和一次（相对昂贵的）大模型并行验证，可能换回多个被接受的Token。理想情况下，这能直接跳过多个解码步骤，从而将解码吞吐量提升数倍。其性能提升取决于草案模型的质量与速度，以及两者之间的协同。它本质上是用计算资源（并行验证能力）来换取更少的串行解码步骤，是突破自回归解码固有延迟瓶颈的最有前景的技术之一。",-1))])}const T=a(d,[["render",h]]),x=JSON.parse('{"path":"/docs/ai-system-engineering/inference-optimization/decoding-strategies.html","title":"解码策略","lang":"zh-CN","frontmatter":{"description":"解码策略 PD 分离 PD 分离，即预填充（Prefill）与解码（Decode）阶段的分离调度。在传统流程中，一个请求必须完整执行完耗时的长提示词预填充计算后，才能开始逐个Token的解码输出，这会导致首个输出Token延迟很高，且在解码时GPU计算核心利用率很低。 PD 分离将这两个阶段解耦为两个独立的虚拟队列。当一批请求到达时，系统优先将所有请求...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"解码策略\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2026-01-30T14:31:16.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"LLMPedia\\",\\"url\\":\\"https://llmpedia.online\\"}]}"],["meta",{"property":"og:url","content":"https://llmpedia.online/docs/ai-system-engineering/inference-optimization/decoding-strategies.html"}],["meta",{"property":"og:site_name","content":"LLMPedia"}],["meta",{"property":"og:title","content":"解码策略"}],["meta",{"property":"og:description","content":"解码策略 PD 分离 PD 分离，即预填充（Prefill）与解码（Decode）阶段的分离调度。在传统流程中，一个请求必须完整执行完耗时的长提示词预填充计算后，才能开始逐个Token的解码输出，这会导致首个输出Token延迟很高，且在解码时GPU计算核心利用率很低。 PD 分离将这两个阶段解耦为两个独立的虚拟队列。当一批请求到达时，系统优先将所有请求..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2026-01-30T14:31:16.000Z"}],["meta",{"property":"article:modified_time","content":"2026-01-30T14:31:16.000Z"}]]},"git":{"createdTime":1769771827000,"updatedTime":1769783476000,"contributors":[{"name":"ge-xiaoxiao","username":"ge-xiaoxiao","email":"marshall_gefxiang@163.com","commits":1,"url":"https://github.com/ge-xiaoxiao"},{"name":"Marshall-Ge","username":"Marshall-Ge","email":"1004083966@qq.com","commits":1,"url":"https://github.com/Marshall-Ge"}]},"readingTime":{"minutes":2.16,"words":649},"filePathRelative":"docs/ai-system-engineering/inference-optimization/decoding-strategies.md","autoDesc":true}');export{T as comp,x as data};
